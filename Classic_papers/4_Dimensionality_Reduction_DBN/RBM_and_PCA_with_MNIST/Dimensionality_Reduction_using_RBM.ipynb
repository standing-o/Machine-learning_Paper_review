{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load MNIST (csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (60000, 785)\n",
      "Test Shape  (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape :\", train_data.shape)\n",
    "print(\"Test Shape \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"label\"], axis = 1).values\n",
    "X_test = test_data.drop([\"label\"], axis = 1).values\n",
    "\n",
    "y_train = train_data.label.values\n",
    "y_test = test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape : (60000, 784)\n",
      "X Test Shape  (10000, 784)\n",
      "y Train Shape : (60000,)\n",
      "y Test Shape  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X Train Shape :\", X_train.shape)\n",
    "print(\"X Test Shape \", X_test.shape)\n",
    "print(\"y Train Shape :\",y_train.shape)\n",
    "print(\"y Test Shape \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RBM (784 -> 196 (14*14) (75% reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "n_visible = 28*28\n",
    "n_hidden = 196\n",
    "display_step = 10\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "lr = tf.constant(0.001, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, n_visible], name = 'x')\n",
    "w = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name = 'w')\n",
    "b_h = tf.Variable(tf.zeros([1, n_hidden], tf.float32, name = 'bh'))\n",
    "b_v = tf.Variable(tf.zeros([1, n_visible], tf.float32, name = 'bv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    \n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(prob):\n",
    "    return tf.floor(prob + tf.random_uniform(tf.shape(prob), 0, 1))\n",
    "\n",
    "def gibbs_step(x_k):\n",
    "    h_k = sample(tf.sigmoid(tf.matmul(x_k, w) + b_h))\n",
    "    x_k = sample(tf.sigmoid(tf.matmul(h_k, tf.transpose(w)) + b_v))\n",
    "    return x_k\n",
    "\n",
    "def gibbs_sample(k, x_k):\n",
    "    for i in range(k):\n",
    "        x_out = gibbs_step(x_k)\n",
    "    return x_out\n",
    "\n",
    "x_s = gibbs_sample(2, x)\n",
    "h_s = sample(tf.sigmoid(tf.matmul(x_s, w) + b_h))\n",
    "\n",
    "h = sample(tf.sigmoid(tf.matmul(x, w) + b_h))\n",
    "x_ = sample(tf.sigmoid(tf.matmul(h, tf.transpose(w)) + b_v))\n",
    "\n",
    "size_batch = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "w_add = tf.multiply(lr/size_batch, tf.subtract(tf.matmul(tf.transpose(x), h), tf.matmul(tf.transpose(x_s), h_s)))\n",
    "bv_add = tf.multiply(lr/size_batch, tf.reduce_sum(tf.subtract(x, x_s), 0, True))\n",
    "bh_add = tf.multiply(lr/size_batch, tf.reduce_sum(tf.subtract(h, h_s), 0, True))\n",
    "updt = [w.assign_add(w_add), b_v.assign_add(bv_add), b_h.assign_add(bh_add)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Epoch : 11\n",
      "Epoch : 21\n",
      "Epoch : 31\n",
      "Epoch : 41\n",
      "Epoch : 51\n",
      "Epoch : 61\n",
      "Epoch : 71\n",
      "Epoch : 81\n",
      "Epoch : 91\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    total_batch = int(X_train.shape[0]/batch_size)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = next_batch(batch_size, X_train, y_train)\n",
    "            batch_xs = (batch_xs>0)*1\n",
    "            _ = sess.run([updt], feed_dict = {x:batch_xs})\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch :\", epoch+1)\n",
    "    print(\"done\")\n",
    "    out1 = sess.run(h, feed_dict = {x: X_train})\n",
    "    out2 = sess.run(h, feed_dict = {x: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (60000, 196)\n",
      "test shape : (10000, 196)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape :\", out1.shape)\n",
    "print(\"test shape :\", out2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(out1)\n",
    "df1.to_csv('x_train_rbm.csv', index=False)\n",
    "df2 = pd.DataFrame(out2)\n",
    "df2.to_csv('x_test_rbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data load test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_train = pd.read_csv('x_train_rbm.csv')\n",
    "rbm_test = pd.read_csv('x_test_rbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape : (60000, 196)\n",
      "test shape : (10000, 196)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape :\", rbm_train.shape)\n",
    "print(\"test shape :\", rbm_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
