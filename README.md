# Machine-learning Paper review
- Machine learning paper review and code implementation
- The summary of papers are recorded in **Issues** (Inspired by kweonwooj's [Github](https://github.com/kweonwooj/papers/issues) :thumbsup:)
- Presentation slides are made for biweekly seminar in SClab & Data analysis club.
- Mainly study on machine learning optimization, Explainable AI (XAI) and time-series forecasting.
- Aug. 19, 2020 ~ Present


## ðŸ‘‰ Table of Contents
- [Optimization](#chart_with_downwards_trend-optimization)
- [XAI](#mag-XAI)
- [Time-series Forecasting](#watch-Time-series-Forecasting)
- [Computer Vision](#tv-computer-vision)
- [Classic Papers (before 2012)](#heavy_check_mark-classic-papers)
-----------------------
## :chart_with_downwards_trend: Optimization
#### 1. [Momentum] On the importance of initialization and momentum in deep learning. | [`[sutskever2013.pdf]`](http://proceedings.mlr.press/v28/sutskever13.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/1) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Optimization/1_Initialization_and_Momentum/20210813_Initialization_and_Momentum.pdf) |

#### 2. [Adam] Adam: A method for stochastic optimization. | [`[kingma2014.pdf]`](https://arxiv.org/pdf/1412.6980.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/2) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Optimization/2_ADAM/20210826_Adaptive_moment_estimation.pdf) |

#### 3. [Dropout] Dropout: a simple way to prevent neural networks from overfitting. | [`[srivastava2014.pdf]`](https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_campaign=buffer&utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/3) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Optimization/3_Dropout/20210907_Dropout.pdf) |   

#### 4. [Batch normalization] Batch normalization: Accelerating deep network training by reducing internal covariate shift. | [`[ioffe2015.pdf]`](https://arxiv.org/pdf/1502.03167.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/4) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Optimization/4_Batch_normalization/20211005_Batch_normalization.pdf) |  

#### 5. [HighwayNet] Training very deep networks. | [`[srivastava2015.pdf]`](https://arxiv.org/pdf/1507.06228.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/5) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Optimization/5_HighwayNet/20211019_HighwayNet_Training_very_deep_networks.pdf) |

#### 6. [He initialization] Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. | [`[he2015.pdf]`](https://arxiv.org/pdf/1502.01852.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/6) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Optimization/6_He_initialization/20211102_He_initialization.pdf) |  

<a href='#table-of-contents'></a>
<br/>
  
## :mag: XAI
#### 1. [2020Survey] Opportunities and challenges in explainable artificial intelligence (XAI): A survey | [`[das2020.pdf]`](https://arxiv.org/pdf/2006.11371.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/8) |  

<a href='#table-of-contents'></a>
<br/>


## :watch: Time-series Forecasting
#### 1. [2021Survey] Time-series forecasting with deep learning: a survey | [`[lim2021]`](https://arxiv.org/pdf/2004.13408.pdf)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/9) |

#### 2. [WaveNet] WaveNet: A generative model for raw audio | [`[van2016]`](https://arxiv.org/abs/1609.03499)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/10) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Time-series_forecasting/20220303_Wavenet.pdf) |

<a href='#table-of-contents'></a>
<br/>

## :tv: Computer Vision
#### 1. [LeNet] Gradient-based learning applied to document recognition. | [`[lecun1998.pdf]`](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791&casa_token=ElGW6XRIra8AAAAA:UDZPHfQO58TTOxZo5Kw-gSpmwo9t7DWe4u197dJuKNUwJ-ZI1TomItrS-7PL0eqnnNXKalMY_Q)
| [Summary](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/issues/7) | [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Computer_vision/1_Lenet/20201201_Lenet.pdf) | [Code](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Computer_vision/1_Lenet/Simple_implementation_of_CNN.ipynb) |

<a href='#table-of-contents'></a>
<br/>
  
## :heavy_check_mark: Classic papers
#### 1. [Turing Machine] On computable numbers, with an application to the Entscheidungsproblem. | [`[turing1936.pdf]`](https://www.wolframscience.com/prizes/tm23/images/Turing.pdf)
| [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/1_Turing_Machine/20200929_Turing_Machine.pdf) | 

#### 2. [Imitation Game] Computing machinery and intelligence. | [`[turing2009.pdf]`](http://www.cse.chalmers.se/~aikmitr/papers/Turing.pdf#page=442)
| [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/2_Imitation_Game/20201006_Imitation_game.pdf) |

#### 3. [Back-propagation] Learning representations by back-propagating errors. | [`[hinton1986.pdf]`](http://www.cs.toronto.edu/~hinton/absps/naturebp.pdf)
| [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/3_Back-Propagation/20201110_Back-Propagation.pdf) | [Code](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/3_Back-Propagation/Simple_implementation_of_back-propagation.ipynb) |

#### 4. [Deep belief net] Reducing the dimensionality of data with neural networks. | [`[hinton2006.pdf]`](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.459.3788&rep=rep1&type=pdf)
| [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/4_Dimensionality_Reduction_DBN/20210121_Dimensionality_Reduction_DBN.pdf) | [Code1](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/4_Dimensionality_Reduction_DBN/AE_and_PCA/Multi-layer_Autoencoder_and_PCA.ipynb), [Code2](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/tree/master/Classic_papers/4_Dimensionality_Reduction_DBN/RBM_and_PCA_with_MNIST) |

- In addition, we conducted a simple study that applied dimensionality reduction using PCA, RBM to classification problems.  
-->> ["Dimensionality reduction methods and Deep learning approach"](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/4_Dimensionality_Reduction_DBN/RBM_and_PCA_with_MNIST/Poster.pdf)

#### 5. [Unsupervised Pretraining] Why does unsupervised pre-training help deep learning? | [`[erhan2010.pdf]`](http://proceedings.mlr.press/v9/erhan10a/erhan10a.pdf) 
| [Presentation](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Classic_papers/5_Unsupervised_Pre-training/20210204_Unsupervised_Pre-training.pdf) | 

<a href='#table-of-contents'></a>
